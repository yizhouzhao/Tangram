{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmeta.datasets.helpers import omniglot\n",
    "from torchmeta.utils.data import BatchMetaDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = omniglot(\"data\", ways=5, shots=5, test_shots=15, meta_train=True, download=True)\n",
    "dataloader = BatchMetaDataLoader(dataset, batch_size=16, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train inputs shape: torch.Size([16, 25, 1, 28, 28])\n",
      "Train targets shape: torch.Size([16, 25])\n",
      "Test inputs shape: torch.Size([16, 75, 1, 28, 28])\n",
      "Test targets shape: torch.Size([16, 75])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    train_inputs, train_targets = batch[\"train\"]\n",
    "    print('Train inputs shape: {0}'.format(train_inputs.shape))    # (16, 25, 1, 28, 28)\n",
    "    print('Train targets shape: {0}'.format(train_targets.shape))  # (16, 25)\n",
    "\n",
    "    test_inputs, test_targets = batch[\"test\"]\n",
    "    print('Test inputs shape: {0}'.format(test_inputs.shape))      # (16, 75, 1, 28, 28)\n",
    "    print('Test targets shape: {0}'.format(test_targets.shape))    # (16, 75)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18247cb4308>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_inputs[0][0][0].data.numpy(),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "from torchmeta.datasets.helpers import omniglot\n",
    "from torchmeta.utils.data import BatchMetaDataLoader\n",
    "from torchmeta.utils.gradient_based import gradient_update_parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchmeta.modules import (MetaModule, MetaSequential, MetaConv2d,\n",
    "                               MetaBatchNorm2d, MetaLinear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, **kwargs):\n",
    "    return MetaSequential(\n",
    "        MetaConv2d(in_channels, out_channels, kernel_size=3, padding=1, **kwargs),\n",
    "        MetaBatchNorm2d(out_channels, momentum=1., track_running_stats=False),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNeuralNetwork(MetaModule):\n",
    "    def __init__(self, in_channels, out_features, hidden_size=64):\n",
    "        super(ConvolutionalNeuralNetwork, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_features = out_features\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.features = MetaSequential(\n",
    "            conv3x3(in_channels, hidden_size),\n",
    "            conv3x3(hidden_size, hidden_size),\n",
    "            conv3x3(hidden_size, hidden_size),\n",
    "            conv3x3(hidden_size, hidden_size)\n",
    "        )\n",
    "\n",
    "        self.classifier = MetaLinear(hidden_size, out_features)\n",
    "\n",
    "    def forward(self, inputs, params=None):\n",
    "        features = self.features(inputs, params=self.get_subdict(params, 'features'))\n",
    "        features = features.view((features.size(0), -1))\n",
    "        logits = self.classifier(features, params=self.get_subdict(params, 'classifier'))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def get_accuracy(logits, targets):\n",
    "    \"\"\"Compute the accuracy (after adaptation) of MAML on the test/query points\n",
    "    Parameters\n",
    "    ----------\n",
    "    logits : `torch.FloatTensor` instance\n",
    "        Outputs/logits of the model on the query points. This tensor has shape\n",
    "        `(num_examples, num_classes)`.\n",
    "    targets : `torch.LongTensor` instance\n",
    "        A tensor containing the targets of the query points. This tensor has \n",
    "        shape `(num_examples,)`.\n",
    "    Returns\n",
    "    -------\n",
    "    accuracy : `torch.FloatTensor` instance\n",
    "        Mean accuracy on the query points\n",
    "    \"\"\"\n",
    "    _, predictions = torch.max(logits, dim=-1)\n",
    "    return torch.mean(predictions.eq(targets).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS():\n",
    "    folder = \"\"\n",
    "    num_shots = 5\n",
    "    num_ways = 5\n",
    "    first_order = None\n",
    "    step_size = 0.4\n",
    "    hidden_size = 64\n",
    "    output_folder = None\n",
    "    batch_size = 16\n",
    "    num_batches = 100\n",
    "    num_workers = 1\n",
    "    download = True\n",
    "    use_cuda = True\n",
    "    device = torch.device('cuda' if use_cuda\n",
    "        and torch.cuda.is_available() else 'cpu')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ARGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This script is an example to showcase the MetaModule and data-loading features of Torchmeta, and as such has been very lightly tested. For a better tested implementation of Model-Agnostic Meta-Learning (MAML) using Torchmeta with more features (including multi-step adaptation and different datasets), please check `https://github.com/tristandeleu/pytorch-maml`.\n"
     ]
    }
   ],
   "source": [
    "logger.warning('This script is an example to showcase the MetaModule and '\n",
    "                   'data-loading features of Torchmeta, and as such has been '\n",
    "                   'very lightly tested. For a better tested implementation of '\n",
    "                   'Model-Agnostic Meta-Learning (MAML) using Torchmeta with '\n",
    "                   'more features (including multi-step adaptation and '\n",
    "                   'different datasets), please check `https://github.com/'\n",
    "                   'tristandeleu/pytorch-maml`.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/brendenlake/omniglot/raw/master/python/images_background.zip to omniglot\\images_background.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97a08fef66f4878a8e5d6eb2b42e0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading https://github.com/brendenlake/omniglot/raw/master/python/images_evaluation.zip to omniglot\\images_evaluation.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f44b355ca54c5bab4528cc7eba54b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = omniglot(args.folder,\n",
    "                       shots=args.num_shots,\n",
    "                       ways=args.num_ways,\n",
    "                       shuffle=True,\n",
    "                       test_shots=15,\n",
    "                       meta_train=True,\n",
    "                       download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
