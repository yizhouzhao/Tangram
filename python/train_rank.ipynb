{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "\n",
    "import PIL\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = \"data/labeldata2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TangramImages(Dataset):\n",
    "    def __init__(self, folder_path,  transforms=None):\n",
    "        self.data_root_folder = folder_path\n",
    "        self.image_list  = self.load_image_list(self.data_root_folder)\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def load_image_list(self, folder_path):\n",
    "        image_list = []\n",
    "        for time_folder in os.listdir(folder_path):\n",
    "            image_folder = os.path.join(folder_path, time_folder)\n",
    "            for file_name in os.listdir(image_folder):\n",
    "                image_list.append(os.path.join(image_folder, file_name))\n",
    "        \n",
    "        return image_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        single_image_path = self.image_list[index]\n",
    "        # Open image\n",
    "        img = PIL.Image.open(single_image_path).convert(\"L\")\n",
    "        img = PIL.ImageOps.invert(img)\n",
    "        #img = resize(img,(IMAGE_SIZE,IMAGE_SIZE))\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "            \n",
    "        score = float(re.split(r\"(\\\\|\\.|/)\",single_image_path)[-3])\n",
    "        return img, score / 8.0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((IMAGE_SIZE,IMAGE_SIZE), interpolation = PIL.Image.NEAREST),\n",
    "    torchvision.transforms.RandomAffine(degrees = 90, translate = (0.2,0.2), scale = (0.6,1)),\n",
    "    torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(),\n",
    "    # torchvision.transforms.RandomRotation(20, resample=PIL.Image.BILINEAR)\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti = TangramImages(f_path, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ti[30][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(ti[30][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Type, Any, Callable, Union, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.models.resnet import BasicBlock, Bottleneck, conv1x1, conv3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ResNet(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         block: Type[Union[BasicBlock, Bottleneck]],\n",
    "#         layers: List[int],\n",
    "#         num_classes: int = 1000,\n",
    "#         zero_init_residual: bool = False,\n",
    "#         groups: int = 1,\n",
    "#         width_per_group: int = 64,\n",
    "#         replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "#         norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "#     ) -> None:\n",
    "#         super(ResNet, self).__init__()\n",
    "#         if norm_layer is None:\n",
    "#             norm_layer = nn.BatchNorm2d\n",
    "#         self._norm_layer = norm_layer\n",
    "\n",
    "#         self.inplanes = 64\n",
    "#         self.dilation = 1\n",
    "#         if replace_stride_with_dilation is None:\n",
    "#             # each element in the tuple indicates if we should replace\n",
    "#             # the 2x2 stride with a dilated convolution instead\n",
    "#             replace_stride_with_dilation = [False, False, False]\n",
    "#         if len(replace_stride_with_dilation) != 3:\n",
    "#             raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "#                              \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "#         self.groups = groups\n",
    "#         self.base_width = width_per_group\n",
    "#         #change 3 -> 1 for gray scale\n",
    "#         self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "#                                bias=False)\n",
    "#         self.bn1 = norm_layer(self.inplanes)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "#         self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "#         self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "#                                        dilate=replace_stride_with_dilation[0])\n",
    "#         self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "#                                        dilate=replace_stride_with_dilation[1])\n",
    "#         self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "#                                        dilate=replace_stride_with_dilation[2])\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "#         self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "#             elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "#                 nn.init.constant_(m.weight, 1)\n",
    "#                 nn.init.constant_(m.bias, 0)\n",
    "\n",
    "#         # Zero-initialize the last BN in each residual branch,\n",
    "#         # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "#         # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "#         if zero_init_residual:\n",
    "#             for m in self.modules():\n",
    "#                 if isinstance(m, Bottleneck):\n",
    "#                     nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
    "#                 elif isinstance(m, BasicBlock):\n",
    "#                     nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
    "\n",
    "#     def _make_layer(self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int,\n",
    "#                     stride: int = 1, dilate: bool = False) -> nn.Sequential:\n",
    "#         norm_layer = self._norm_layer\n",
    "#         downsample = None\n",
    "#         previous_dilation = self.dilation\n",
    "#         if dilate:\n",
    "#             self.dilation *= stride\n",
    "#             stride = 1\n",
    "#         if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "#             downsample = nn.Sequential(\n",
    "#                 conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "#                 norm_layer(planes * block.expansion),\n",
    "#             )\n",
    "\n",
    "#         layers = []\n",
    "#         layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "#                             self.base_width, previous_dilation, norm_layer))\n",
    "#         self.inplanes = planes * block.expansion\n",
    "#         for _ in range(1, blocks):\n",
    "#             layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "#                                 base_width=self.base_width, dilation=self.dilation,\n",
    "#                                 norm_layer=norm_layer))\n",
    "\n",
    "#         return nn.Sequential(*layers)\n",
    "\n",
    "#     def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "#         # See note [TorchScript super()]\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.maxpool(x)\n",
    "\n",
    "#         x = self.layer1(x)\n",
    "#         x = self.layer2(x)\n",
    "#         x = self.layer3(x)\n",
    "#         x = self.layer4(x)\n",
    "\n",
    "#         x = self.avgpool(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.fc(x)\n",
    "\n",
    "#         return x\n",
    "\n",
    "#     def forward(self, x: Tensor) -> Tensor:\n",
    "#         return self._forward_impl(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##model = ResNet(BasicBlock, [1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ti_dataloader = DataLoader(ti, batch_size=4,\n",
    "#                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for batch_input, batch_label in ti_dataloader:\n",
    "#    print(batch_input, batch_label)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model(batch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, **kwargs):\n",
    "    # The convolutional layers (for feature extraction) use standard layers from\n",
    "    # `torch.nn`, since they do not require adaptation.\n",
    "    # See `examples/maml/model.py` for comparison.\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, **kwargs),\n",
    "        nn.BatchNorm2d(out_channels, momentum=1., track_running_stats=False),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNeuralNetwork(nn.Module):\n",
    "    def __init__(self, in_channels, out_features, hidden_size=64):\n",
    "        super(ConvolutionalNeuralNetwork, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_features = out_features\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            conv3x3(in_channels, hidden_size),\n",
    "            conv3x3(hidden_size, hidden_size),\n",
    "            conv3x3(hidden_size, hidden_size),\n",
    "            conv3x3(hidden_size, hidden_size)\n",
    "        )\n",
    "\n",
    "        # Only the last (linear) layer is used for adaptation in ANIL\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(hidden_size, out_features),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, params=None):\n",
    "        features = self.features(inputs)\n",
    "        #print(features.shape)\n",
    "        features = features.view((features.size(0), -1))\n",
    "        #print(features.shape)\n",
    "        scores = self.linear(features)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvolutionalNeuralNetwork(1, 1, hidden_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(batch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_len = int(0.95 * len(ti))\n",
    "test_dataset_len = len(ti) - train_dataset_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(ti,[train_dataset_len, test_dataset_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 avg loss 0.70\n",
      "epoch: 1 avg loss 0.45\n",
      "epoch: 2 avg loss 0.42\n",
      "epoch: 3 avg loss 0.42\n",
      "epoch: 4 avg loss 0.39\n",
      "epoch: 5 avg loss 0.41\n",
      "epoch: 6 avg loss 0.37\n",
      "epoch: 7 avg loss 0.39\n",
      "epoch: 8 avg loss 0.37\n",
      "epoch: 9 avg loss 0.37\n",
      "epoch: 10 avg loss 0.37\n",
      "epoch: 11 avg loss 0.37\n",
      "epoch: 12 avg loss 0.36\n",
      "epoch: 13 avg loss 0.34\n",
      "epoch: 14 avg loss 0.33\n",
      "epoch: 15 avg loss 0.34\n",
      "epoch: 16 avg loss 0.35\n",
      "epoch: 17 avg loss 0.34\n",
      "epoch: 18 avg loss 0.34\n",
      "epoch: 19 avg loss 0.33\n",
      "epoch: 20 avg loss 0.34\n",
      "epoch: 21 avg loss 0.33\n",
      "epoch: 22 avg loss 0.33\n",
      "epoch: 23 avg loss 0.33\n",
      "epoch: 24 avg loss 0.31\n",
      "epoch: 25 avg loss 0.33\n",
      "epoch: 26 avg loss 0.35\n",
      "epoch: 27 avg loss 0.33\n",
      "epoch: 28 avg loss 0.33\n",
      "epoch: 29 avg loss 0.33\n",
      "epoch: 30 avg loss 0.34\n",
      "epoch: 31 avg loss 0.34\n",
      "epoch: 32 avg loss 0.33\n",
      "epoch: 33 avg loss 0.32\n",
      "epoch: 34 avg loss 0.33\n",
      "epoch: 35 avg loss 0.33\n",
      "epoch: 36 avg loss 0.31\n",
      "epoch: 37 avg loss 0.31\n",
      "epoch: 38 avg loss 0.34\n",
      "epoch: 39 avg loss 0.30\n",
      "epoch: 40 avg loss 0.29\n",
      "epoch: 41 avg loss 0.31\n",
      "epoch: 42 avg loss 0.31\n",
      "epoch: 43 avg loss 0.32\n",
      "epoch: 44 avg loss 0.32\n",
      "epoch: 45 avg loss 0.34\n",
      "epoch: 46 avg loss 0.31\n",
      "epoch: 47 avg loss 0.31\n",
      "epoch: 48 avg loss 0.32\n",
      "epoch: 49 avg loss 0.32\n",
      "epoch: 50 avg loss 0.30\n",
      "epoch: 51 avg loss 0.31\n",
      "epoch: 52 avg loss 0.31\n",
      "epoch: 53 avg loss 0.32\n",
      "epoch: 54 avg loss 0.30\n",
      "epoch: 55 avg loss 0.30\n",
      "epoch: 56 avg loss 0.33\n",
      "epoch: 57 avg loss 0.30\n",
      "epoch: 58 avg loss 0.30\n",
      "epoch: 59 avg loss 0.31\n",
      "epoch: 60 avg loss 0.31\n",
      "epoch: 61 avg loss 0.30\n",
      "epoch: 62 avg loss 0.30\n",
      "epoch: 63 avg loss 0.29\n",
      "epoch: 64 avg loss 0.29\n",
      "epoch: 65 avg loss 0.30\n",
      "epoch: 66 avg loss 0.31\n",
      "epoch: 67 avg loss 0.31\n",
      "epoch: 68 avg loss 0.30\n",
      "epoch: 69 avg loss 0.30\n",
      "epoch: 70 avg loss 0.29\n",
      "epoch: 71 avg loss 0.30\n",
      "epoch: 72 avg loss 0.30\n",
      "epoch: 73 avg loss 0.29\n",
      "epoch: 74 avg loss 0.31\n",
      "epoch: 75 avg loss 0.30\n",
      "epoch: 76 avg loss 0.31\n",
      "epoch: 77 avg loss 0.29\n",
      "epoch: 78 avg loss 0.28\n",
      "epoch: 79 avg loss 0.29\n",
      "epoch: 80 avg loss 0.28\n",
      "epoch: 81 avg loss 0.30\n",
      "epoch: 82 avg loss 0.27\n",
      "epoch: 83 avg loss 0.29\n",
      "epoch: 84 avg loss 0.28\n",
      "epoch: 85 avg loss 0.28\n",
      "epoch: 86 avg loss 0.29\n",
      "epoch: 87 avg loss 0.29\n",
      "epoch: 88 avg loss 0.28\n",
      "epoch: 89 avg loss 0.28\n",
      "epoch: 90 avg loss 0.28\n",
      "epoch: 91 avg loss 0.29\n",
      "epoch: 92 avg loss 0.26\n",
      "epoch: 93 avg loss 0.29\n",
      "epoch: 94 avg loss 0.28\n",
      "epoch: 95 avg loss 0.27\n",
      "epoch: 96 avg loss 0.30\n",
      "epoch: 97 avg loss 0.29\n",
      "epoch: 98 avg loss 0.28\n",
      "epoch: 99 avg loss 0.28\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    loss_epoch = []\n",
    "    count = 0\n",
    "    for batch_inputs, batch_scores in train_dataloader:\n",
    "        count += 1\n",
    "        #print(batch_inputs.shape)\n",
    "        if torch.cuda.is_available():\n",
    "            batch_inputs = batch_inputs.to(\"cuda\")\n",
    "            batch_scores = batch_scores.to(\"cuda\")\n",
    "        \n",
    "        pred_scores = model(batch_inputs).view(-1)\n",
    "        \n",
    "        loss = torch.sum((pred_scores - batch_scores)**2)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_epoch.append(loss.item())\n",
    "        \n",
    "        # if count % 20 == 0:\n",
    "        #    print(loss)\n",
    "        \n",
    "    print(\"epoch: {} avg loss {:.2f}\".format(epoch, sum(loss_epoch)/(len(loss_epoch) + 1e-3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"10_31_2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('features.0.0.weight',\n",
       "              tensor([[[[ 0.0111,  0.0524,  0.2606],\n",
       "                        [-0.2092, -0.1338,  0.1465],\n",
       "                        [-0.0704, -0.2544, -0.0135]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1751,  0.2248, -0.0237],\n",
       "                        [ 0.0573, -0.2224,  0.1846],\n",
       "                        [-0.2693, -0.3187, -0.1637]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1354,  0.1638,  0.3037],\n",
       "                        [-0.1084, -0.2364, -0.1252],\n",
       "                        [-0.0553,  0.0251, -0.1426]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1337, -0.0077, -0.2621],\n",
       "                        [-0.3046,  0.2932,  0.2450],\n",
       "                        [-0.1187,  0.2944,  0.2961]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0381, -0.2808, -0.2079],\n",
       "                        [-0.2697,  0.3243, -0.2935],\n",
       "                        [ 0.1715, -0.0540,  0.2164]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0968, -0.1115, -0.2445],\n",
       "                        [ 0.2132,  0.0776,  0.1858],\n",
       "                        [ 0.2559, -0.0695,  0.0893]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1978, -0.2596,  0.2136],\n",
       "                        [ 0.2892,  0.2439,  0.3234],\n",
       "                        [-0.0125,  0.3232,  0.0983]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1511,  0.2726,  0.0602],\n",
       "                        [ 0.0078, -0.2853, -0.1064],\n",
       "                        [-0.1356,  0.2601,  0.3124]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2922,  0.1942,  0.1365],\n",
       "                        [-0.1917,  0.1043,  0.2417],\n",
       "                        [-0.0865,  0.0198,  0.0663]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1925,  0.2242, -0.3338],\n",
       "                        [ 0.1676,  0.1978,  0.0852],\n",
       "                        [ 0.2504, -0.1282, -0.3276]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2090,  0.1923,  0.2009],\n",
       "                        [ 0.3050,  0.1329, -0.1509],\n",
       "                        [ 0.2038,  0.1836, -0.0667]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0124, -0.3040, -0.2652],\n",
       "                        [ 0.3470, -0.0833,  0.3041],\n",
       "                        [ 0.0644, -0.2927, -0.0785]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1586,  0.1207,  0.1736],\n",
       "                        [-0.0207, -0.1145, -0.2287],\n",
       "                        [ 0.0408, -0.3128,  0.2650]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2028, -0.2765, -0.0009],\n",
       "                        [ 0.2641,  0.0005, -0.2567],\n",
       "                        [ 0.3109, -0.2098,  0.0984]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0713,  0.1424,  0.0126],\n",
       "                        [ 0.1137,  0.3264,  0.0736],\n",
       "                        [-0.1565, -0.1864,  0.1625]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3360,  0.1043, -0.2861],\n",
       "                        [ 0.2856, -0.1161,  0.0745],\n",
       "                        [-0.1520,  0.2603,  0.0660]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3022, -0.1786,  0.2304],\n",
       "                        [-0.3327,  0.1245,  0.2779],\n",
       "                        [-0.0120,  0.0473, -0.2694]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1187,  0.0779, -0.2648],\n",
       "                        [ 0.1711, -0.0769,  0.2805],\n",
       "                        [ 0.3324,  0.0442,  0.1944]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1376, -0.2259, -0.0648],\n",
       "                        [-0.1994, -0.1707,  0.2044],\n",
       "                        [ 0.2544, -0.2712, -0.2444]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1997,  0.0129, -0.1617],\n",
       "                        [ 0.1425, -0.0239, -0.1525],\n",
       "                        [-0.2394,  0.2748, -0.0819]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0674, -0.0252, -0.0943],\n",
       "                        [-0.3171,  0.0355,  0.2589],\n",
       "                        [ 0.0484, -0.0315,  0.2755]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2159, -0.3085, -0.1581],\n",
       "                        [ 0.1782, -0.2749,  0.0467],\n",
       "                        [ 0.2112,  0.2768,  0.1536]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2379,  0.1557, -0.1702],\n",
       "                        [ 0.0993,  0.0973, -0.3157],\n",
       "                        [ 0.2768,  0.2337,  0.1405]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2051, -0.1110, -0.1313],\n",
       "                        [ 0.2453, -0.1394,  0.3273],\n",
       "                        [ 0.2852,  0.0286,  0.0578]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1348,  0.0850,  0.2693],\n",
       "                        [ 0.1002,  0.1855,  0.1092],\n",
       "                        [-0.2182,  0.1342, -0.2991]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0998, -0.3154,  0.1542],\n",
       "                        [ 0.2825,  0.1985, -0.3368],\n",
       "                        [-0.1958,  0.0303, -0.0142]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2248, -0.1265,  0.1151],\n",
       "                        [ 0.3161, -0.0434, -0.0852],\n",
       "                        [ 0.1778,  0.2218, -0.0484]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2190,  0.2202, -0.1369],\n",
       "                        [-0.2652,  0.2066, -0.1013],\n",
       "                        [ 0.1993,  0.2712,  0.2984]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1087, -0.0076, -0.0851],\n",
       "                        [-0.1313,  0.0010, -0.0611],\n",
       "                        [-0.1918,  0.1510,  0.1836]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2864, -0.0084, -0.3274],\n",
       "                        [-0.2728, -0.0738,  0.1268],\n",
       "                        [ 0.3323,  0.1630, -0.1168]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0381,  0.0729,  0.0469],\n",
       "                        [ 0.0881,  0.1517, -0.0893],\n",
       "                        [-0.1415, -0.2549, -0.2324]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1169, -0.0777, -0.2756],\n",
       "                        [ 0.1544,  0.2516, -0.2706],\n",
       "                        [-0.0806, -0.1785,  0.1157]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1695, -0.2799,  0.0570],\n",
       "                        [-0.2847, -0.1247, -0.0507],\n",
       "                        [-0.0383,  0.1107,  0.1901]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1275, -0.3189,  0.0061],\n",
       "                        [-0.0980, -0.2964,  0.0566],\n",
       "                        [-0.0549,  0.3254,  0.0799]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2096,  0.2133,  0.0448],\n",
       "                        [-0.2519,  0.0574, -0.1186],\n",
       "                        [ 0.2732, -0.1188, -0.3156]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0116,  0.0997,  0.1403],\n",
       "                        [ 0.0990,  0.0418,  0.2376],\n",
       "                        [-0.0078,  0.2007, -0.1517]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0611,  0.0830,  0.2624],\n",
       "                        [-0.3319,  0.1153, -0.2690],\n",
       "                        [ 0.1926, -0.0964, -0.1288]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3654, -0.2468,  0.1402],\n",
       "                        [ 0.2466, -0.0940,  0.1555],\n",
       "                        [ 0.0266,  0.2475, -0.0064]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1698, -0.1718, -0.2019],\n",
       "                        [ 0.0583,  0.0327,  0.2019],\n",
       "                        [-0.1081,  0.2055, -0.1842]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0857, -0.3187,  0.2869],\n",
       "                        [ 0.0573,  0.0067, -0.1241],\n",
       "                        [ 0.0633,  0.0352,  0.1817]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1041,  0.0903, -0.0496],\n",
       "                        [-0.1389,  0.1703, -0.2380],\n",
       "                        [ 0.2971,  0.2564,  0.0345]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2530, -0.1838,  0.1098],\n",
       "                        [-0.0744,  0.2920,  0.2977],\n",
       "                        [-0.0059,  0.2314, -0.0683]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1310,  0.2452,  0.1295],\n",
       "                        [-0.2980, -0.2011,  0.2515],\n",
       "                        [ 0.0630, -0.1326, -0.2425]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0304,  0.1512,  0.1258],\n",
       "                        [-0.2860,  0.2055,  0.1082],\n",
       "                        [-0.1802, -0.2572,  0.0799]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0462,  0.1468, -0.1185],\n",
       "                        [-0.1250,  0.1305,  0.0175],\n",
       "                        [-0.0352, -0.1797,  0.0198]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2616, -0.0461, -0.3173],\n",
       "                        [-0.0588,  0.2757,  0.3130],\n",
       "                        [ 0.2961,  0.2453,  0.1961]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1629,  0.1327, -0.1200],\n",
       "                        [-0.2438,  0.2003,  0.1911],\n",
       "                        [-0.0859,  0.2653,  0.1506]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2497,  0.2078, -0.2527],\n",
       "                        [ 0.1595,  0.1023,  0.1061],\n",
       "                        [-0.1881,  0.0482, -0.2270]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0196,  0.0401,  0.3409],\n",
       "                        [ 0.3153,  0.2355,  0.1689],\n",
       "                        [-0.2664, -0.2965,  0.0513]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1692,  0.1735, -0.2840],\n",
       "                        [ 0.1030,  0.3151,  0.3099],\n",
       "                        [-0.0018, -0.2789, -0.0422]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2085,  0.0863,  0.1110],\n",
       "                        [ 0.3030,  0.0392,  0.3257],\n",
       "                        [ 0.0943, -0.2246,  0.1508]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1819,  0.1998, -0.2602],\n",
       "                        [ 0.0536,  0.1074,  0.0264],\n",
       "                        [ 0.2584, -0.2895,  0.2735]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0830, -0.2636, -0.2813],\n",
       "                        [-0.2607,  0.0266, -0.0825],\n",
       "                        [-0.2145, -0.0957,  0.1026]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0071, -0.3133,  0.3304],\n",
       "                        [ 0.1706, -0.1605, -0.3282],\n",
       "                        [-0.2710, -0.2600,  0.2875]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2434,  0.1470,  0.0559],\n",
       "                        [ 0.1432,  0.0404,  0.2076],\n",
       "                        [ 0.2644,  0.2363, -0.1354]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0032,  0.0063,  0.2200],\n",
       "                        [-0.1184, -0.1987, -0.0919],\n",
       "                        [ 0.1268, -0.0201,  0.3152]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2208,  0.0040, -0.1317],\n",
       "                        [ 0.1903, -0.2908, -0.2163],\n",
       "                        [ 0.2221, -0.0094,  0.0263]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0152,  0.0529,  0.1877],\n",
       "                        [ 0.0619, -0.0103, -0.0408],\n",
       "                        [ 0.2323,  0.0926,  0.2193]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2668,  0.2036, -0.0497],\n",
       "                        [ 0.0456, -0.3567,  0.2839],\n",
       "                        [ 0.0351, -0.0266, -0.1710]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2302,  0.2567, -0.0717],\n",
       "                        [ 0.0275, -0.1407, -0.0033],\n",
       "                        [-0.3224, -0.0067,  0.1162]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0480,  0.2938, -0.1680],\n",
       "                        [ 0.0033,  0.1454, -0.2346],\n",
       "                        [ 0.0258,  0.0321, -0.0745]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2938,  0.0068, -0.2073],\n",
       "                        [-0.0461, -0.0597,  0.2594],\n",
       "                        [ 0.2005,  0.1075, -0.0545]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0669, -0.1382,  0.1174],\n",
       "                        [-0.3364, -0.0476,  0.2702],\n",
       "                        [ 0.2767,  0.1025, -0.2032]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0053, -0.0851, -0.2316],\n",
       "                        [-0.1255,  0.3194,  0.0266],\n",
       "                        [ 0.1538,  0.0885,  0.0381]]]], device='cuda:0')),\n",
       "             ('features.0.0.bias',\n",
       "              tensor([ 2.0539e-01,  1.1186e-01, -2.1217e-01, -3.1912e-01,  3.3665e-01,\n",
       "                      -6.0264e-02, -5.5664e-05,  2.8591e-01, -2.4217e-01, -3.0299e-02,\n",
       "                      -3.6947e-02, -1.6686e-01, -3.0936e-01, -1.0792e-01,  3.1824e-01,\n",
       "                       3.6917e-02,  1.1965e-01, -1.2814e-01, -1.3922e-02, -1.2742e-01,\n",
       "                      -2.3039e-01, -2.5454e-01,  6.2611e-02, -3.9065e-02,  5.3038e-02,\n",
       "                      -2.3800e-01,  2.3680e-01, -1.6893e-01,  2.9699e-02, -1.9713e-01,\n",
       "                      -2.4414e-02, -2.3892e-01, -6.2317e-02, -1.7622e-01,  2.9544e-01,\n",
       "                       2.0454e-01, -2.0182e-01, -9.2155e-02,  2.5135e-01, -2.4302e-01,\n",
       "                      -1.2949e-01,  4.2438e-02,  7.3666e-02,  1.7523e-01,  2.1870e-01,\n",
       "                       1.8899e-01, -9.3823e-02, -2.5647e-01, -6.7209e-02, -2.2478e-01,\n",
       "                       2.0907e-01, -1.8499e-01,  3.0910e-01, -1.2811e-01, -2.7907e-01,\n",
       "                       4.5473e-02,  1.5471e-01,  3.6590e-02,  1.4972e-01,  9.8444e-02,\n",
       "                      -1.9225e-01, -6.0959e-02,  1.7855e-01,  3.2499e-01], device='cuda:0')),\n",
       "             ('features.0.1.weight',\n",
       "              tensor([1.0079, 1.0244, 1.0217, 0.9945, 0.9970, 0.9864, 0.9873, 0.9898, 0.9923,\n",
       "                      1.0012, 0.9938, 1.0307, 0.9902, 1.0199, 0.9806, 0.9908, 1.0223, 0.9816,\n",
       "                      1.0376, 0.9918, 0.9936, 0.9933, 0.9860, 0.9755, 0.9924, 1.0039, 0.9930,\n",
       "                      1.0027, 1.0401, 1.0066, 1.0555, 1.0298, 1.0253, 1.0149, 0.9848, 1.0057,\n",
       "                      0.9712, 0.9820, 1.0442, 0.9785, 0.9890, 0.9860, 1.0222, 1.0025, 1.0066,\n",
       "                      0.9955, 0.9902, 1.0566, 0.9937, 0.9746, 0.9824, 0.9826, 1.0269, 1.0256,\n",
       "                      0.9839, 0.9858, 1.0024, 1.0011, 0.9895, 0.9764, 1.0195, 0.9899, 0.9787,\n",
       "                      0.9941], device='cuda:0')),\n",
       "             ('features.0.1.bias',\n",
       "              tensor([-1.0374e-02,  3.0399e-02,  6.6724e-03, -2.0592e-02,  1.9571e-02,\n",
       "                      -1.7346e-02, -7.4372e-03, -7.3572e-03, -6.0203e-03,  7.2468e-04,\n",
       "                      -5.6781e-03, -1.2905e-02, -1.3713e-02, -3.2100e-02, -2.0278e-02,\n",
       "                       2.1040e-03, -8.6084e-03, -1.0486e-02,  9.2795e-04, -1.2714e-03,\n",
       "                      -3.5656e-03,  3.9399e-03, -1.2261e-02, -2.2876e-02, -1.8234e-02,\n",
       "                      -3.7963e-03, -2.2167e-02,  5.1604e-03, -9.9183e-03,  2.0494e-02,\n",
       "                      -9.3836e-03,  1.2525e-02, -2.2693e-02,  3.9053e-03, -1.9853e-02,\n",
       "                      -1.8556e-03,  8.1557e-03, -1.4748e-02,  2.7676e-03, -1.3690e-02,\n",
       "                      -2.3897e-02, -5.3167e-03,  1.3669e-02,  1.7430e-02, -1.6855e-02,\n",
       "                      -5.5197e-03,  2.3824e-03,  4.6765e-02, -1.1996e-02, -2.7706e-02,\n",
       "                       2.2381e-03, -1.9204e-02,  2.4864e-02,  2.2274e-02, -7.9827e-03,\n",
       "                      -7.8548e-03,  1.3227e-02,  7.5924e-03,  8.1995e-03, -2.5443e-02,\n",
       "                       1.2675e-02,  5.4201e-03, -1.1963e-02,  1.6948e-05], device='cuda:0')),\n",
       "             ('features.1.0.weight',\n",
       "              tensor([[[[ 2.7691e-02,  2.5319e-03,  2.8532e-03],\n",
       "                        [-3.6698e-02, -3.6980e-02, -1.0747e-02],\n",
       "                        [-1.0163e-02,  4.0411e-02,  4.2853e-02]],\n",
       "              \n",
       "                       [[-5.8470e-02,  1.5079e-02,  2.3277e-02],\n",
       "                        [-8.6560e-03, -2.5738e-02, -3.5749e-02],\n",
       "                        [-1.0124e-02,  4.1901e-02, -2.4762e-02]],\n",
       "              \n",
       "                       [[-1.2144e-02,  2.9609e-02,  1.7899e-02],\n",
       "                        [-1.9448e-02,  3.5645e-02,  1.5438e-02],\n",
       "                        [-3.9707e-03,  5.4129e-03, -2.3516e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.3422e-02,  2.5614e-02, -4.2398e-02],\n",
       "                        [-4.2379e-02,  2.4776e-03, -4.3081e-02],\n",
       "                        [-3.7721e-02, -3.7655e-02,  1.4054e-02]],\n",
       "              \n",
       "                       [[-2.1940e-02, -2.1300e-02,  2.3373e-02],\n",
       "                        [-1.1654e-02, -1.1329e-02, -1.5050e-02],\n",
       "                        [ 4.4442e-02, -3.5323e-02,  3.2643e-02]],\n",
       "              \n",
       "                       [[-9.8769e-03, -8.4742e-03,  3.7834e-02],\n",
       "                        [ 1.7982e-02,  2.5501e-02,  3.8308e-02],\n",
       "                        [-3.7143e-02, -3.0680e-02, -4.1050e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.3919e-02,  3.7858e-02, -1.5489e-02],\n",
       "                        [ 1.2146e-03,  2.2495e-03,  1.5829e-02],\n",
       "                        [-4.2858e-03, -3.6562e-02,  5.4486e-02]],\n",
       "              \n",
       "                       [[-2.1811e-02, -4.8503e-02, -1.3198e-02],\n",
       "                        [-3.4759e-03,  5.7747e-03,  6.1909e-03],\n",
       "                        [-2.1885e-02, -4.2802e-03, -7.3942e-04]],\n",
       "              \n",
       "                       [[ 4.2480e-02,  2.5348e-02,  1.5537e-02],\n",
       "                        [ 2.2343e-02, -3.6555e-02,  3.0746e-02],\n",
       "                        [-6.6821e-04, -1.1792e-02,  3.4200e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.1707e-02, -2.8761e-02,  2.6452e-02],\n",
       "                        [ 4.0636e-02, -4.8770e-02,  4.0970e-03],\n",
       "                        [ 1.3882e-02,  3.2085e-02,  1.8549e-02]],\n",
       "              \n",
       "                       [[ 1.2434e-02,  1.7129e-02, -5.2757e-03],\n",
       "                        [-2.8271e-02,  3.2155e-02, -1.2773e-04],\n",
       "                        [-8.2179e-03, -1.3214e-02, -1.0406e-02]],\n",
       "              \n",
       "                       [[-2.4709e-03,  4.5427e-03, -1.2538e-02],\n",
       "                        [ 4.1668e-02,  1.2785e-02,  2.1471e-03],\n",
       "                        [ 8.1176e-03,  4.5713e-02,  1.8087e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.3420e-02,  3.4218e-03,  7.5508e-03],\n",
       "                        [-1.3319e-02,  3.3610e-02, -2.6335e-03],\n",
       "                        [-1.0948e-02, -2.4582e-03, -1.2867e-02]],\n",
       "              \n",
       "                       [[-2.2311e-03,  1.1262e-02, -3.7804e-03],\n",
       "                        [-1.5462e-03,  2.0362e-02, -2.6066e-02],\n",
       "                        [-1.5278e-02,  7.1571e-03, -2.7523e-02]],\n",
       "              \n",
       "                       [[-4.2718e-02,  1.7400e-02,  4.2843e-02],\n",
       "                        [-1.7057e-02, -1.4116e-02, -2.2084e-02],\n",
       "                        [ 1.3030e-03,  4.1168e-02,  4.1362e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.9587e-02, -1.2563e-02,  1.3783e-02],\n",
       "                        [-4.3676e-02, -1.7323e-02,  2.3613e-02],\n",
       "                        [ 2.4024e-03,  5.4370e-03, -3.5887e-03]],\n",
       "              \n",
       "                       [[-4.0625e-02,  3.7676e-02, -6.1317e-03],\n",
       "                        [ 2.4653e-02,  9.1175e-03, -3.1330e-02],\n",
       "                        [-1.7291e-02,  2.0817e-02, -3.3286e-02]],\n",
       "              \n",
       "                       [[-2.0791e-02,  1.2140e-03,  1.3195e-02],\n",
       "                        [ 3.6046e-02, -1.2744e-02, -3.6391e-02],\n",
       "                        [-1.7189e-02,  2.7360e-02, -2.3507e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 2.0427e-02, -2.3172e-02, -3.4983e-02],\n",
       "                        [ 2.4273e-02, -2.1820e-02, -3.5857e-02],\n",
       "                        [-4.5413e-02,  3.3225e-02,  3.3271e-02]],\n",
       "              \n",
       "                       [[ 2.2221e-02,  2.3312e-02, -4.3825e-02],\n",
       "                        [-4.1665e-03,  1.8737e-02,  2.5007e-02],\n",
       "                        [ 2.2249e-02,  3.8767e-02, -9.1358e-03]],\n",
       "              \n",
       "                       [[-3.0085e-02, -4.0896e-02, -1.4324e-02],\n",
       "                        [ 1.3881e-02, -2.0466e-02, -2.2766e-02],\n",
       "                        [-1.3864e-02, -1.0068e-02, -4.4110e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.8505e-03, -3.0464e-02,  5.0092e-02],\n",
       "                        [ 4.5879e-02, -5.7177e-03, -3.6249e-02],\n",
       "                        [-2.7539e-02,  4.6084e-02, -5.0486e-02]],\n",
       "              \n",
       "                       [[ 2.4316e-02, -1.9230e-02,  1.2536e-02],\n",
       "                        [ 4.0802e-02,  9.7927e-03, -2.0691e-02],\n",
       "                        [ 2.5162e-02,  2.0582e-02,  2.2376e-03]],\n",
       "              \n",
       "                       [[-2.4816e-02, -3.7870e-03, -2.7154e-02],\n",
       "                        [-1.7491e-02, -1.2832e-02, -2.5245e-02],\n",
       "                        [ 3.2059e-02, -3.3506e-03, -4.4894e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2782e-02, -7.2693e-03,  2.0079e-03],\n",
       "                        [ 3.0455e-02, -1.8018e-02, -5.5019e-03],\n",
       "                        [-3.1037e-02,  1.5431e-02,  5.0606e-03]],\n",
       "              \n",
       "                       [[ 2.7601e-03,  1.5354e-02, -6.0370e-02],\n",
       "                        [ 2.7088e-02, -4.3673e-02, -2.2424e-02],\n",
       "                        [-2.4936e-02,  2.4797e-02, -1.1543e-03]],\n",
       "              \n",
       "                       [[ 2.7543e-03, -2.7124e-02, -1.6452e-02],\n",
       "                        [ 1.7665e-02,  7.7077e-03, -1.0131e-02],\n",
       "                        [ 3.5102e-02, -3.2531e-02,  1.0218e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.7405e-02, -3.8937e-02,  1.0186e-02],\n",
       "                        [-7.3527e-03, -2.6165e-02,  1.9799e-02],\n",
       "                        [ 3.0423e-02, -5.7691e-03,  7.5857e-03]],\n",
       "              \n",
       "                       [[ 9.2660e-03, -3.0074e-02,  1.3391e-02],\n",
       "                        [-1.7703e-03,  2.1888e-02, -3.5198e-02],\n",
       "                        [-2.1929e-02, -4.9034e-04, -1.8700e-03]],\n",
       "              \n",
       "                       [[-3.5578e-02,  2.3221e-02, -1.9934e-02],\n",
       "                        [-3.0597e-02,  5.6865e-03,  6.5131e-03],\n",
       "                        [ 6.6951e-03,  3.8854e-02, -1.9518e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.1346e-02,  2.8384e-02, -1.8007e-02],\n",
       "                        [ 2.6721e-02,  5.5057e-02,  2.3009e-02],\n",
       "                        [ 2.0857e-02,  3.0982e-02,  2.7764e-02]],\n",
       "              \n",
       "                       [[ 2.1632e-02,  1.8302e-02, -8.6023e-03],\n",
       "                        [ 1.1405e-02,  9.8506e-03, -4.0253e-02],\n",
       "                        [-4.0132e-03,  1.8622e-02, -4.0896e-02]],\n",
       "              \n",
       "                       [[ 4.7335e-02, -1.8893e-02, -2.7763e-02],\n",
       "                        [ 6.7242e-03,  4.1376e-02,  2.1028e-02],\n",
       "                        [ 5.1262e-03,  5.1822e-02, -2.3233e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.4863e-02,  5.0067e-04, -2.4480e-02],\n",
       "                        [-4.6006e-02, -3.3403e-02,  3.7303e-02],\n",
       "                        [-2.2642e-02,  1.1475e-02,  3.0296e-02]],\n",
       "              \n",
       "                       [[ 2.3914e-02,  2.4860e-02, -2.9866e-03],\n",
       "                        [ 2.4957e-02,  4.2409e-02,  3.4027e-02],\n",
       "                        [-2.7498e-02,  1.5812e-02, -2.1419e-02]],\n",
       "              \n",
       "                       [[-3.1404e-02,  6.9926e-03,  4.1764e-03],\n",
       "                        [-1.3210e-02,  3.0918e-05, -2.0027e-02],\n",
       "                        [-3.3167e-02, -2.3241e-02, -1.5510e-02]]]], device='cuda:0')),\n",
       "             ('features.1.0.bias',\n",
       "              tensor([-3.7763e-02, -2.5213e-02,  3.7874e-02, -5.6060e-03, -2.3269e-02,\n",
       "                       1.5313e-02,  3.3684e-02, -3.5891e-02, -8.9802e-03, -3.9829e-02,\n",
       "                      -2.0220e-02,  1.9783e-02,  2.7768e-02, -1.3960e-02, -3.5194e-02,\n",
       "                       3.6871e-03, -3.7238e-02, -3.0499e-02, -6.6566e-03,  1.9825e-02,\n",
       "                       1.8344e-02, -1.0325e-02,  5.4761e-03, -3.7883e-03,  3.5062e-03,\n",
       "                       3.8312e-02,  9.1201e-03, -5.2730e-03, -1.1879e-02,  2.1931e-03,\n",
       "                      -3.1358e-02, -3.9056e-03,  3.9104e-02,  8.4827e-05, -3.7413e-02,\n",
       "                      -2.5513e-03, -8.5911e-03, -2.2031e-02,  3.8784e-02, -1.4398e-02,\n",
       "                      -8.7815e-03, -5.8465e-03, -1.5485e-02,  2.0558e-02, -8.7551e-03,\n",
       "                      -2.0799e-02, -8.4750e-03, -3.0070e-02,  2.0088e-02, -3.9079e-02,\n",
       "                       1.5748e-02,  2.1965e-02,  2.2853e-02,  2.7418e-02,  1.7906e-02,\n",
       "                       6.3022e-03, -2.4101e-03, -2.9666e-02,  6.9419e-03, -1.9843e-02,\n",
       "                       2.2998e-03, -2.3759e-02, -3.4761e-04,  2.6592e-03], device='cuda:0')),\n",
       "             ('features.1.1.weight',\n",
       "              tensor([0.9864, 1.0258, 1.0021, 0.9993, 1.0087, 1.0090, 1.0103, 0.9923, 0.9979,\n",
       "                      1.0092, 1.0003, 0.9795, 1.0127, 0.9951, 0.9878, 0.9982, 0.9866, 1.0033,\n",
       "                      0.9925, 0.9842, 0.9863, 1.0113, 0.9937, 0.9941, 0.9854, 1.0149, 1.0100,\n",
       "                      0.9977, 0.9966, 0.9875, 0.9924, 0.9874, 0.9955, 1.0121, 0.9949, 0.9957,\n",
       "                      1.0196, 1.0108, 1.0020, 1.0008, 1.0116, 0.9885, 0.9877, 0.9937, 0.9858,\n",
       "                      0.9967, 0.9868, 1.0031, 0.9980, 0.9976, 0.9974, 1.0071, 0.9810, 1.0110,\n",
       "                      0.9950, 1.0067, 0.9970, 1.0250, 1.0157, 0.9979, 1.0150, 0.9887, 0.9910,\n",
       "                      0.9924], device='cuda:0')),\n",
       "             ('features.1.1.bias',\n",
       "              tensor([ 1.2220e-02,  8.1121e-03, -1.1396e-03, -9.7934e-03,  1.1214e-02,\n",
       "                       6.3810e-03,  1.5163e-02,  2.8387e-03, -1.9857e-03, -1.2699e-03,\n",
       "                       5.0860e-03, -1.6873e-02, -1.4309e-02, -1.7749e-02, -4.6699e-03,\n",
       "                      -2.3217e-03,  7.4836e-03, -9.9457e-03, -2.3959e-03,  1.0454e-02,\n",
       "                      -8.4431e-03, -5.9003e-03, -5.3229e-03, -5.4074e-03, -1.7543e-03,\n",
       "                      -7.6688e-03, -5.4424e-03, -1.3166e-02, -6.3775e-03, -6.1301e-04,\n",
       "                      -1.8910e-02, -9.4228e-03, -4.9670e-03, -1.1509e-02, -1.1193e-02,\n",
       "                       1.8725e-03,  6.1154e-03,  1.1295e-03,  3.1506e-03, -9.1157e-03,\n",
       "                       2.1153e-05, -1.2155e-02, -2.1171e-02, -1.1678e-02, -7.0534e-03,\n",
       "                       1.9531e-03, -6.4200e-03,  1.3676e-02, -9.7725e-05,  1.2169e-02,\n",
       "                       6.0764e-03, -6.7881e-03, -1.5946e-02, -1.4760e-02, -7.8223e-03,\n",
       "                      -4.2194e-03, -1.5095e-02, -3.2688e-04,  2.0468e-02, -6.9257e-03,\n",
       "                       3.2517e-04, -7.7419e-03, -1.5860e-02,  2.2380e-03], device='cuda:0')),\n",
       "             ('features.2.0.weight',\n",
       "              tensor([[[[ 2.8767e-02, -2.1534e-02,  2.3506e-03],\n",
       "                        [ 1.5430e-02, -3.3619e-02, -1.4193e-03],\n",
       "                        [ 8.3452e-03,  1.4447e-02, -1.7816e-02]],\n",
       "              \n",
       "                       [[-3.1282e-03,  4.8509e-03,  3.9367e-02],\n",
       "                        [ 8.9183e-03,  1.3795e-02,  4.3723e-02],\n",
       "                        [-7.3112e-03, -2.3085e-02, -1.3072e-02]],\n",
       "              \n",
       "                       [[ 2.5387e-02, -2.9041e-02,  1.0979e-03],\n",
       "                        [ 1.3273e-02,  4.6957e-02, -1.5494e-02],\n",
       "                        [ 3.3188e-02, -1.8494e-02, -4.0807e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0972e-02, -4.4198e-02,  2.2288e-02],\n",
       "                        [-3.6837e-02, -2.4524e-02, -3.0580e-02],\n",
       "                        [ 1.3766e-02, -1.1481e-02, -6.7122e-03]],\n",
       "              \n",
       "                       [[ 4.4497e-02, -3.1672e-02, -2.5690e-02],\n",
       "                        [ 4.6878e-02,  1.9478e-02,  4.0748e-02],\n",
       "                        [-1.1020e-02, -3.5346e-02,  3.8707e-02]],\n",
       "              \n",
       "                       [[-2.7539e-02,  1.0156e-02,  9.8165e-03],\n",
       "                        [-3.9540e-02,  2.2347e-02,  3.4692e-02],\n",
       "                        [-3.0627e-02,  3.9557e-02, -1.7946e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9187e-03,  3.2794e-02, -3.8304e-02],\n",
       "                        [ 6.5294e-03, -3.5070e-02,  2.7699e-04],\n",
       "                        [ 2.6305e-02,  1.0737e-02,  3.7557e-02]],\n",
       "              \n",
       "                       [[ 3.0795e-03,  2.3325e-02, -2.5469e-02],\n",
       "                        [-2.0537e-02, -2.4769e-02, -2.0402e-02],\n",
       "                        [ 2.1591e-02, -1.7052e-02, -4.6016e-02]],\n",
       "              \n",
       "                       [[-6.1943e-04,  1.9270e-02, -2.3013e-02],\n",
       "                        [ 4.4036e-03, -2.8290e-02,  1.2500e-02],\n",
       "                        [-1.2530e-02, -4.0064e-02, -1.2458e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.6585e-02, -9.5060e-03,  3.0318e-02],\n",
       "                        [ 5.5723e-04,  2.1042e-02, -3.9860e-02],\n",
       "                        [-3.8692e-02, -1.0014e-02,  1.3578e-02]],\n",
       "              \n",
       "                       [[ 8.2497e-03, -1.8583e-02,  2.4631e-02],\n",
       "                        [-8.2823e-03,  1.4099e-02, -2.5399e-02],\n",
       "                        [ 4.1714e-02, -3.0314e-02, -3.0438e-02]],\n",
       "              \n",
       "                       [[-4.8253e-06, -7.7860e-03, -2.5152e-02],\n",
       "                        [ 3.8150e-02,  1.1179e-02,  2.8350e-02],\n",
       "                        [-1.9146e-02, -4.0122e-02, -5.0496e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.0150e-02, -2.8758e-03,  1.5395e-03],\n",
       "                        [-2.8424e-03,  2.5812e-02,  2.7280e-02],\n",
       "                        [ 2.1010e-03,  3.3460e-02, -2.3673e-02]],\n",
       "              \n",
       "                       [[-5.2801e-02, -4.8331e-02,  1.4941e-02],\n",
       "                        [ 6.4659e-03, -3.0604e-03, -5.4506e-03],\n",
       "                        [-5.8065e-03,  1.5812e-02, -4.0293e-02]],\n",
       "              \n",
       "                       [[ 2.5812e-02,  2.2027e-02,  1.9535e-02],\n",
       "                        [-2.8452e-02, -2.5609e-03,  3.2786e-02],\n",
       "                        [-2.1035e-02, -7.1170e-03, -2.6782e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.2416e-02, -3.1211e-02, -9.0320e-04],\n",
       "                        [-2.6636e-02,  1.3440e-02,  8.6424e-03],\n",
       "                        [-2.4260e-02,  1.9811e-02,  9.8993e-03]],\n",
       "              \n",
       "                       [[ 3.0717e-02, -3.4533e-02, -2.4547e-02],\n",
       "                        [-2.2280e-02, -2.7197e-02, -2.3749e-02],\n",
       "                        [-4.0868e-02,  1.9441e-02, -2.9993e-02]],\n",
       "              \n",
       "                       [[ 1.4900e-02, -1.7791e-02, -1.3516e-02],\n",
       "                        [ 2.4798e-02,  2.4831e-02, -1.8176e-02],\n",
       "                        [-7.8076e-03, -3.0983e-03, -2.6153e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9109e-02, -1.8575e-02, -3.1181e-02],\n",
       "                        [-7.7751e-03,  2.6749e-02, -4.1811e-02],\n",
       "                        [-1.1249e-02, -4.5584e-03,  1.4350e-02]],\n",
       "              \n",
       "                       [[ 4.1142e-02, -4.7628e-03, -2.7131e-02],\n",
       "                        [ 3.5890e-02,  8.2028e-03, -2.5702e-03],\n",
       "                        [-3.7964e-02, -8.6903e-03, -2.7849e-02]],\n",
       "              \n",
       "                       [[ 2.3448e-02,  1.3519e-02, -1.8881e-02],\n",
       "                        [-3.2665e-03,  1.7772e-02, -3.5179e-02],\n",
       "                        [-2.6252e-02, -1.9664e-02,  2.3376e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 8.1432e-03,  1.2623e-02, -2.3094e-02],\n",
       "                        [ 2.7444e-02,  4.4889e-02,  2.9826e-02],\n",
       "                        [-1.7104e-02, -2.1288e-02,  4.5023e-02]],\n",
       "              \n",
       "                       [[-3.5443e-02,  2.9352e-02, -5.1061e-03],\n",
       "                        [-1.6756e-02,  4.7653e-02, -2.0777e-02],\n",
       "                        [-2.0890e-02,  1.3411e-02, -1.2548e-02]],\n",
       "              \n",
       "                       [[-3.9812e-03,  3.0518e-02, -4.3560e-02],\n",
       "                        [-3.0091e-02,  2.4560e-02, -1.6262e-02],\n",
       "                        [ 3.0974e-02, -3.2701e-03, -3.6908e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.1571e-04,  3.9960e-02,  1.9420e-02],\n",
       "                        [-1.6299e-02,  8.9709e-03,  2.1389e-02],\n",
       "                        [-4.1956e-02, -1.7587e-02, -4.7593e-02]],\n",
       "              \n",
       "                       [[-1.2091e-03,  5.0364e-02,  2.3546e-03],\n",
       "                        [ 9.8735e-03,  8.8325e-03, -2.0565e-02],\n",
       "                        [-2.3692e-02, -2.1955e-02,  1.2707e-02]],\n",
       "              \n",
       "                       [[-1.5959e-02, -1.5578e-02, -1.3533e-02],\n",
       "                        [ 1.3090e-02, -2.4842e-02, -2.1153e-02],\n",
       "                        [-3.1481e-02, -3.8805e-02, -9.7198e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.7500e-02,  2.7507e-02, -1.8575e-02],\n",
       "                        [-1.9988e-02, -3.7213e-02,  1.9795e-02],\n",
       "                        [ 1.1622e-02, -4.4569e-02,  2.9029e-02]],\n",
       "              \n",
       "                       [[ 4.1168e-02,  3.2978e-02,  1.6517e-02],\n",
       "                        [-4.1191e-02,  3.3071e-02, -3.5979e-02],\n",
       "                        [-1.2140e-02, -4.4658e-02, -3.9990e-02]],\n",
       "              \n",
       "                       [[ 3.2672e-03,  3.4656e-02,  1.7562e-02],\n",
       "                        [ 1.6122e-02, -1.2402e-02,  4.0027e-02],\n",
       "                        [-2.8018e-02, -2.6190e-02,  8.1970e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.9358e-02, -3.9590e-02, -3.6693e-02],\n",
       "                        [ 1.8463e-02, -2.7741e-02,  1.6563e-02],\n",
       "                        [ 3.4227e-02,  3.4309e-02,  3.9849e-02]],\n",
       "              \n",
       "                       [[-4.0974e-02, -3.2989e-02, -6.9256e-03],\n",
       "                        [-8.3785e-03, -3.6796e-02, -1.9755e-02],\n",
       "                        [ 3.3836e-02, -3.0344e-02, -2.4499e-03]],\n",
       "              \n",
       "                       [[-4.3521e-03,  5.3345e-03, -4.6620e-02],\n",
       "                        [-2.2221e-02,  3.7478e-02,  1.6110e-03],\n",
       "                        [-2.6979e-02,  3.8327e-02,  1.1548e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.9201e-03, -1.9972e-02,  1.8877e-02],\n",
       "                        [ 1.7202e-02, -2.6973e-03,  2.0499e-02],\n",
       "                        [-1.7368e-02, -9.9614e-03, -2.1026e-02]],\n",
       "              \n",
       "                       [[ 1.6464e-02, -3.4921e-02, -1.1450e-02],\n",
       "                        [ 1.5335e-02, -7.8525e-04,  4.2807e-02],\n",
       "                        [-4.3431e-02, -1.2154e-02,  3.2318e-02]],\n",
       "              \n",
       "                       [[-2.1380e-02,  2.5251e-02,  1.1534e-02],\n",
       "                        [-1.0556e-02,  8.7728e-03,  5.0921e-02],\n",
       "                        [-3.1581e-02,  4.7552e-02,  1.1817e-02]]]], device='cuda:0')),\n",
       "             ('features.2.0.bias',\n",
       "              tensor([-0.0407, -0.0225, -0.0369, -0.0226,  0.0021, -0.0262, -0.0244,  0.0396,\n",
       "                      -0.0395, -0.0213,  0.0014,  0.0094, -0.0384, -0.0295, -0.0285, -0.0197,\n",
       "                      -0.0361, -0.0017,  0.0283, -0.0356, -0.0368,  0.0186, -0.0291, -0.0031,\n",
       "                      -0.0072,  0.0239,  0.0283, -0.0141,  0.0185,  0.0254,  0.0322,  0.0073,\n",
       "                      -0.0330,  0.0318, -0.0173,  0.0317,  0.0249,  0.0342,  0.0356, -0.0239,\n",
       "                      -0.0211, -0.0273, -0.0017, -0.0254, -0.0233, -0.0055, -0.0071, -0.0397,\n",
       "                      -0.0279, -0.0162, -0.0033,  0.0315, -0.0389,  0.0370, -0.0233, -0.0031,\n",
       "                       0.0189, -0.0286, -0.0394,  0.0267, -0.0096, -0.0313, -0.0222,  0.0055],\n",
       "                     device='cuda:0')),\n",
       "             ('features.2.1.weight',\n",
       "              tensor([0.9901, 1.0094, 0.9708, 1.0262, 0.9931, 1.0002, 0.9950, 1.0043, 1.0060,\n",
       "                      0.9860, 1.0042, 0.9705, 1.0105, 0.9889, 0.9950, 1.0030, 1.0011, 1.0098,\n",
       "                      0.9791, 0.9989, 1.0032, 1.0110, 0.9914, 1.0052, 1.0038, 0.9932, 1.0055,\n",
       "                      0.9815, 0.9993, 0.9927, 0.9780, 1.0094, 1.0059, 0.9866, 0.9915, 1.0084,\n",
       "                      0.9826, 0.9953, 1.0001, 0.9899, 0.9951, 0.9876, 1.0026, 0.9884, 1.0114,\n",
       "                      1.0004, 1.0034, 1.0041, 1.0031, 0.9941, 1.0203, 1.0244, 1.0040, 1.0117,\n",
       "                      0.9948, 0.9969, 1.0011, 0.9990, 1.0041, 1.0204, 1.0033, 1.0099, 0.9616,\n",
       "                      0.9934], device='cuda:0')),\n",
       "             ('features.2.1.bias',\n",
       "              tensor([-1.1845e-02,  1.6549e-02, -1.8842e-02,  2.0967e-03, -2.6618e-03,\n",
       "                       7.5601e-03,  1.6941e-03, -7.6039e-03,  3.5860e-03, -6.9310e-03,\n",
       "                      -3.6008e-03, -1.8690e-02,  9.3604e-03, -9.3365e-03, -9.0797e-03,\n",
       "                       1.5843e-03, -1.3870e-03, -5.5160e-03,  4.1965e-03, -3.1710e-03,\n",
       "                       1.0284e-03,  5.2995e-03, -1.3149e-02,  9.0999e-05, -8.0497e-03,\n",
       "                       5.4677e-03,  5.0260e-03, -2.2861e-02, -4.5210e-03, -1.1843e-02,\n",
       "                      -2.2237e-02,  1.1426e-02,  8.7101e-04, -1.2479e-02, -8.8234e-04,\n",
       "                       5.6319e-03, -1.8909e-02, -5.0940e-03,  4.2056e-04, -1.0591e-02,\n",
       "                       4.3683e-04, -1.5710e-02,  3.5783e-03,  3.5003e-03, -7.0331e-03,\n",
       "                      -8.0940e-04,  1.0746e-02, -7.6797e-03, -1.9757e-03, -4.2896e-03,\n",
       "                       6.4448e-03,  1.3348e-02, -4.3578e-03, -1.0266e-04, -9.1611e-03,\n",
       "                      -9.5930e-03, -4.9097e-03,  4.2579e-03,  2.6813e-03, -3.8819e-04,\n",
       "                       4.5689e-03, -9.1111e-03, -1.9290e-02, -1.0249e-02], device='cuda:0')),\n",
       "             ('features.3.0.weight',\n",
       "              tensor([[[[-3.5603e-02, -2.0045e-02,  1.9744e-02],\n",
       "                        [-8.7676e-03, -3.5258e-02,  4.6001e-02],\n",
       "                        [-1.2456e-02, -1.1076e-02,  2.2739e-02]],\n",
       "              \n",
       "                       [[ 4.0656e-02,  2.8516e-02,  2.8610e-02],\n",
       "                        [-2.3726e-02, -3.9339e-02,  2.1478e-02],\n",
       "                        [ 4.1652e-02, -2.2430e-02,  5.5626e-02]],\n",
       "              \n",
       "                       [[-1.2500e-02,  3.4863e-03, -2.5624e-02],\n",
       "                        [ 7.4451e-03,  1.7555e-02, -1.2868e-03],\n",
       "                        [ 1.8519e-02, -1.0613e-02,  4.5751e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.2105e-02, -4.0811e-02, -3.4129e-02],\n",
       "                        [-1.9709e-02, -1.7398e-02,  1.4112e-02],\n",
       "                        [-2.1357e-02,  2.2962e-02,  5.3444e-02]],\n",
       "              \n",
       "                       [[-3.8643e-02,  3.0312e-02, -1.8407e-02],\n",
       "                        [-4.4083e-02, -3.6335e-02, -1.5094e-02],\n",
       "                        [-9.2130e-03, -1.9128e-02,  2.0532e-02]],\n",
       "              \n",
       "                       [[-5.3881e-03,  3.2229e-02,  2.1360e-02],\n",
       "                        [ 1.5995e-03, -7.4343e-03,  2.5588e-02],\n",
       "                        [ 1.1475e-02,  2.0955e-02,  8.8512e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.3787e-02,  3.5836e-02,  6.6120e-03],\n",
       "                        [ 2.0384e-02,  3.3374e-02, -2.6463e-02],\n",
       "                        [-1.6763e-02,  2.5103e-02,  2.0567e-02]],\n",
       "              \n",
       "                       [[ 2.9298e-02, -3.8577e-03, -3.3489e-02],\n",
       "                        [-3.8947e-02, -3.7876e-02,  1.5161e-02],\n",
       "                        [-9.0560e-03,  1.6253e-02, -3.8761e-02]],\n",
       "              \n",
       "                       [[ 1.3305e-02, -3.8081e-02,  7.6222e-03],\n",
       "                        [-2.9265e-02, -3.7385e-02, -2.2917e-02],\n",
       "                        [-9.8305e-03, -1.1545e-02,  2.2243e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.4239e-02,  2.4149e-02, -2.6276e-02],\n",
       "                        [-1.7118e-02, -1.0934e-02,  2.6699e-02],\n",
       "                        [-3.4559e-02, -1.1465e-02, -9.4947e-04]],\n",
       "              \n",
       "                       [[-2.5926e-02,  6.6514e-03,  5.6691e-03],\n",
       "                        [-1.5013e-02, -2.1250e-02, -2.0771e-02],\n",
       "                        [-2.6135e-02, -2.2172e-02, -3.1503e-03]],\n",
       "              \n",
       "                       [[-5.1436e-03, -1.2034e-02, -4.7574e-02],\n",
       "                        [ 2.8594e-02, -2.5590e-02, -2.1755e-02],\n",
       "                        [ 7.4729e-03, -1.8377e-02, -5.8921e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.4541e-02,  3.7952e-02, -4.2136e-02],\n",
       "                        [-4.0670e-02, -3.9519e-02, -4.4842e-02],\n",
       "                        [ 2.7029e-02,  4.5263e-03, -1.4803e-02]],\n",
       "              \n",
       "                       [[-2.4531e-02,  6.5652e-05, -4.3713e-02],\n",
       "                        [-2.2100e-02,  1.1765e-02, -1.6016e-02],\n",
       "                        [-4.5867e-02, -2.0872e-02,  1.5767e-02]],\n",
       "              \n",
       "                       [[ 3.6178e-03, -2.4528e-02, -2.9527e-02],\n",
       "                        [ 2.4865e-02, -3.2548e-02,  7.0011e-03],\n",
       "                        [-1.0847e-02,  3.0143e-04,  1.5675e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.5977e-02, -2.2229e-02, -1.2865e-02],\n",
       "                        [ 2.6330e-02,  2.9407e-02, -1.4504e-02],\n",
       "                        [-4.4259e-02, -2.6042e-02, -5.2281e-02]],\n",
       "              \n",
       "                       [[-3.1236e-03, -3.7961e-02,  3.0435e-02],\n",
       "                        [ 2.4491e-02, -3.0208e-03, -1.3945e-04],\n",
       "                        [-2.4992e-02, -3.0690e-02, -3.8918e-02]],\n",
       "              \n",
       "                       [[ 3.7041e-02,  3.0293e-02, -2.4521e-02],\n",
       "                        [ 2.6718e-02, -2.8185e-02, -1.5487e-02],\n",
       "                        [-2.1600e-02, -3.3638e-02, -2.8836e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4930e-04, -1.7356e-02, -5.0032e-03],\n",
       "                        [ 1.6378e-02,  9.6102e-03, -3.7439e-02],\n",
       "                        [-2.7146e-02,  5.2379e-03,  3.0075e-02]],\n",
       "              \n",
       "                       [[ 1.0417e-02, -5.2270e-03, -5.4862e-03],\n",
       "                        [ 1.2792e-02, -4.2409e-02, -5.0458e-02],\n",
       "                        [-3.3361e-02,  1.9376e-02, -2.0063e-02]],\n",
       "              \n",
       "                       [[-7.8300e-03, -1.6433e-03, -4.4749e-02],\n",
       "                        [-1.0530e-02, -2.0943e-02,  1.0883e-02],\n",
       "                        [ 3.0645e-02, -2.1681e-02, -1.8165e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.3097e-02,  3.1199e-02,  9.7257e-03],\n",
       "                        [ 1.8695e-02, -1.8057e-03, -3.1975e-02],\n",
       "                        [-2.2815e-02,  2.8242e-02,  8.6043e-04]],\n",
       "              \n",
       "                       [[ 5.8415e-03,  2.4432e-03, -4.9187e-02],\n",
       "                        [-1.4989e-03, -1.9801e-02, -2.3264e-02],\n",
       "                        [ 2.1199e-02,  6.4232e-03,  1.3175e-02]],\n",
       "              \n",
       "                       [[-1.5655e-02, -2.3162e-04,  3.8069e-02],\n",
       "                        [ 4.5165e-02,  2.9941e-02,  2.6452e-02],\n",
       "                        [ 4.5357e-03, -2.5037e-02,  2.5598e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.3719e-02,  8.7084e-04,  2.6127e-02],\n",
       "                        [-3.0048e-02,  3.7475e-02, -4.1585e-02],\n",
       "                        [-2.4371e-02,  1.4072e-02,  2.3767e-02]],\n",
       "              \n",
       "                       [[ 3.7527e-02,  3.7609e-02, -3.7893e-02],\n",
       "                        [-2.7701e-02, -5.9101e-03,  1.7940e-02],\n",
       "                        [-2.5459e-03,  4.7125e-04, -4.1291e-02]],\n",
       "              \n",
       "                       [[-3.2243e-03, -8.7089e-03,  3.5187e-02],\n",
       "                        [-3.7007e-02,  8.7583e-04,  1.4846e-02],\n",
       "                        [-1.3866e-02,  1.5545e-02,  1.9205e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.4495e-02,  9.4172e-04,  3.6676e-02],\n",
       "                        [-8.0198e-03, -6.6653e-03,  4.9811e-03],\n",
       "                        [ 2.5291e-02,  3.9545e-02, -5.0540e-02]],\n",
       "              \n",
       "                       [[-2.5373e-02, -1.3150e-02, -2.7802e-02],\n",
       "                        [ 1.8905e-02, -1.6385e-02, -3.7750e-03],\n",
       "                        [-6.2576e-03,  3.6882e-02,  2.5636e-02]],\n",
       "              \n",
       "                       [[ 3.2004e-02,  3.8447e-02, -1.2791e-02],\n",
       "                        [ 3.4814e-02,  1.4296e-02, -3.3398e-02],\n",
       "                        [-2.9968e-02, -8.2956e-03,  1.1621e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.2935e-02, -2.7244e-02,  1.2130e-02],\n",
       "                        [-1.5217e-02,  2.5529e-02, -9.2335e-03],\n",
       "                        [ 1.1635e-02,  7.9152e-05,  4.1818e-02]],\n",
       "              \n",
       "                       [[ 2.0993e-02, -5.0681e-03, -6.4229e-03],\n",
       "                        [ 1.6769e-02, -4.6359e-03,  1.2305e-02],\n",
       "                        [-8.5308e-03,  6.4987e-04, -4.7670e-02]],\n",
       "              \n",
       "                       [[-1.2629e-02,  1.4584e-02, -2.8581e-02],\n",
       "                        [-5.8354e-03, -1.1295e-02,  1.4124e-02],\n",
       "                        [ 1.0341e-03, -3.7888e-02,  1.6336e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.7571e-02,  5.4231e-03,  4.7773e-02],\n",
       "                        [-2.5645e-02,  1.4060e-02,  2.1000e-02],\n",
       "                        [ 9.5485e-03,  1.7428e-03, -2.7848e-02]],\n",
       "              \n",
       "                       [[-1.9601e-02,  3.3337e-02,  3.3374e-02],\n",
       "                        [-2.9773e-02,  4.0449e-02, -8.6841e-03],\n",
       "                        [ 3.8453e-02, -1.5837e-02,  1.7937e-02]],\n",
       "              \n",
       "                       [[-9.8024e-04,  3.7940e-02, -1.2754e-02],\n",
       "                        [-2.6825e-02,  1.4881e-02,  1.5283e-02],\n",
       "                        [ 1.4901e-02,  3.8669e-02,  2.6172e-02]]]], device='cuda:0')),\n",
       "             ('features.3.0.bias',\n",
       "              tensor([ 0.0266, -0.0058,  0.0348, -0.0255, -0.0086, -0.0398,  0.0249, -0.0310,\n",
       "                       0.0220, -0.0376,  0.0154, -0.0352,  0.0394, -0.0168,  0.0350, -0.0379,\n",
       "                      -0.0052,  0.0352, -0.0107, -0.0023,  0.0369, -0.0263, -0.0291,  0.0160,\n",
       "                       0.0189, -0.0335, -0.0437, -0.0351, -0.0242, -0.0155, -0.0274, -0.0186,\n",
       "                      -0.0197, -0.0302, -0.0039,  0.0387, -0.0075, -0.0005, -0.0273,  0.0123,\n",
       "                       0.0123, -0.0271,  0.0259,  0.0199,  0.0238,  0.0235,  0.0129, -0.0155,\n",
       "                       0.0401, -0.0346,  0.0389, -0.0367,  0.0302, -0.0067, -0.0030, -0.0189,\n",
       "                       0.0028,  0.0211, -0.0256,  0.0103,  0.0338, -0.0183, -0.0224,  0.0200],\n",
       "                     device='cuda:0')),\n",
       "             ('features.3.1.weight',\n",
       "              tensor([1.0006, 0.9815, 0.9847, 0.9698, 1.0016, 0.9855, 0.9897, 0.9937, 1.0165,\n",
       "                      0.9974, 0.9965, 0.9999, 0.9993, 0.9894, 0.9988, 0.9971, 1.0042, 0.9941,\n",
       "                      1.0043, 0.9886, 0.9924, 0.9926, 1.0041, 1.0031, 1.0010, 0.9919, 1.0033,\n",
       "                      1.0042, 0.9960, 1.0043, 1.0023, 1.0005, 0.9974, 0.9975, 1.0128, 1.0276,\n",
       "                      0.9899, 1.0430, 0.9934, 0.9963, 0.9961, 0.9918, 0.9928, 1.0056, 1.0221,\n",
       "                      0.9995, 1.0018, 1.0056, 1.0026, 1.0580, 1.0006, 0.9922, 0.9948, 1.0006,\n",
       "                      0.9976, 0.9937, 0.9998, 1.0033, 1.0298, 0.9962, 0.9955, 0.9877, 0.9940,\n",
       "                      1.0010], device='cuda:0')),\n",
       "             ('features.3.1.bias',\n",
       "              tensor([ 0.0055, -0.0132, -0.0200, -0.0114,  0.0056, -0.0033, -0.0065,  0.0028,\n",
       "                       0.0109,  0.0049,  0.0002,  0.0051,  0.0026,  0.0048,  0.0023,  0.0035,\n",
       "                       0.0054, -0.0043,  0.0057, -0.0078,  0.0003, -0.0005,  0.0055,  0.0041,\n",
       "                       0.0053, -0.0042, -0.0054,  0.0051,  0.0009,  0.0054,  0.0045,  0.0051,\n",
       "                      -0.0023, -0.0004,  0.0088,  0.0007, -0.0028,  0.0038,  0.0028,  0.0044,\n",
       "                       0.0029,  0.0020, -0.0060,  0.0055,  0.0062, -0.0014,  0.0041,  0.0046,\n",
       "                       0.0048,  0.0079,  0.0055, -0.0068, -0.0067,  0.0050,  0.0047,  0.0047,\n",
       "                       0.0047,  0.0054,  0.0038,  0.0019, -0.0043, -0.0081,  0.0005,  0.0057],\n",
       "                     device='cuda:0')),\n",
       "             ('linear.0.weight',\n",
       "              tensor([[-0.0618,  0.0905,  0.0355,  0.0868, -0.0513,  0.0775,  0.1039, -0.0830,\n",
       "                       -0.1249, -0.0538,  0.0542, -0.0353,  0.0716, -0.0851,  0.0848,  0.0487,\n",
       "                       -0.0499,  0.0714, -0.1233,  0.0122,  0.0702, -0.0470, -0.0890, -0.0230,\n",
       "                       -0.1149,  0.0867,  0.1009, -0.0332,  0.0678, -0.0824, -0.0630, -0.0850,\n",
       "                        0.0810,  0.0548, -0.1272, -0.0880,  0.0964, -0.0699,  0.0989,  0.0823,\n",
       "                       -0.0155,  0.0727,  0.1163, -0.0728, -0.1399,  0.0140,  0.0314, -0.0408,\n",
       "                       -0.0576, -0.1240, -0.1084,  0.0556,  0.0437, -0.0723, -0.0145, -0.1009,\n",
       "                       -0.0425, -0.0797, -0.0872,  0.0273, -0.0073,  0.0032,  0.0738,  0.0606]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear.0.bias', tensor([0.0334], device='cuda:0'))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11726039399558574"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(0.22/16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
